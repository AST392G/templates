{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790b4d74-92f2-4535-a46b-d633f299cbd8",
   "metadata": {},
   "source": [
    "# Starter code for measuring angular separations on the sky\n",
    "\n",
    "## Learning goals\n",
    "The purpose of this noteobok is to familiarize yourself with reading, plotting, and determining the statistics of fits images from the 30inch telescope. As a secondary goal we will also impplemenet a *VERY BASIC*  CCD Reduction (without many bells and whistles that will be needed when we do a final data reduction). \n",
    "\n",
    "We will start by loading in the nessisary libraries. Inside the libraries exists defintions (functions) that allow us to carry out what we want the code to do. We will also then load in the data set needed \n",
    "\n",
    "Lets begin!\n",
    "\n",
    "## Data Location : \n",
    "UTBox  [256MB]: https://utexas.box.com/s/728urjnexttq1v6jdkntp3raeb89mz3w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58b5504-8f66-44b0-9df3-87fe75f483c1",
   "metadata": {},
   "source": [
    "## Loading Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e847c33-6562-413f-a61d-d9a0f86e9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "#remove if you dont have a startup file\n",
    "from startup import *\n",
    "#-----\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as p\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from scipy import stats\n",
    "from astropy.nddata import CCDData\n",
    "import ccdproc\n",
    "from ccdproc import ImageFileCollection, Combiner, combine\n",
    "import glob\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import ZScaleInterval\n",
    "zscale = ZScaleInterval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "#Add useful show_image defintion \n",
    "\n",
    "\n",
    "def show_image(image,\n",
    "               percl=99, percu=None, is_mask=False,\n",
    "               figsize=(10, 10),\n",
    "               cmap='viridis', log=False, clip=True,\n",
    "               show_colorbar=True, show_ticks=True,\n",
    "               fig=None, ax=None, input_ratio=None):\n",
    "    \"\"\"\n",
    "    Show an image in matplotlib with some basic astronomically-appropriate stretching. \n",
    "    Taken from https://github.com/astropy/ccd-reduction-and-photometry-guide/blob/main/notebooks/convenience_functions.py\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image\n",
    "        The image to show\n",
    "    percl : number\n",
    "        The percentile for the lower edge of the stretch (or both edges if ``percu`` is None)\n",
    "    percu : number or None\n",
    "        The percentile for the upper edge of the stretch (or None to use ``percl`` for both)\n",
    "    figsize : 2-tuple\n",
    "        The size of the matplotlib figure in inches\n",
    "    \"\"\"\n",
    "    if percu is None:\n",
    "        percu = percl\n",
    "        percl = 100 - percl\n",
    "\n",
    "    if (fig is None and ax is not None) or (fig is not None and ax is None):\n",
    "        raise ValueError('Must provide both \"fig\" and \"ax\" '\n",
    "                         'if you provide one of them')\n",
    "    elif fig is None and ax is None:\n",
    "        if figsize is not None:\n",
    "            # Rescale the fig size to match the image dimensions, roughly\n",
    "            image_aspect_ratio = image.shape[0] / image.shape[1]\n",
    "            figsize = (max(figsize) * image_aspect_ratio, max(figsize))\n",
    "\n",
    "        fig, ax = p.subplots(1, 1, figsize=figsize)\n",
    "\n",
    "\n",
    "    # To preserve details we should *really* downsample correctly and\n",
    "    # not rely on matplotlib to do it correctly for us (it won't).\n",
    "\n",
    "    # So, calculate the size of the figure in pixels, block_reduce to\n",
    "    # roughly that,and display the block reduced image.\n",
    "\n",
    "    # Thanks, https://stackoverflow.com/questions/29702424/how-to-get-matplotlib-figure-size\n",
    "    fig_size_pix = fig.get_size_inches() * fig.dpi\n",
    "\n",
    "    ratio = (image.shape // fig_size_pix).max()\n",
    "\n",
    "    if ratio < 1:\n",
    "        ratio = 1\n",
    "\n",
    "    ratio = input_ratio or ratio\n",
    "\n",
    "    reduced_data = block_reduce(image, ratio)\n",
    "\n",
    "    if not is_mask:\n",
    "        # Divide by the square of the ratio to keep the flux the same in the\n",
    "        # reduced image. We do *not* want to do this for images which are\n",
    "        # masks, since their values should be zero or one.\n",
    "         reduced_data = reduced_data / ratio**2\n",
    "\n",
    "    # Of course, now that we have downsampled, the axis limits are changed to\n",
    "    # match the smaller image size. Setting the extent will do the trick to\n",
    "    # change the axis display back to showing the actual extent of the image.\n",
    "    extent = [0, image.shape[1], 0, image.shape[0]]\n",
    "\n",
    "    if log:\n",
    "        stretch = aviz.LogStretch()\n",
    "    else:\n",
    "        stretch = aviz.LinearStretch()\n",
    "\n",
    "    norm = aviz.ImageNormalize(reduced_data,\n",
    "                               interval=aviz.AsymmetricPercentileInterval(percl, percu),\n",
    "                               stretch=stretch, clip=clip)\n",
    "\n",
    "    if is_mask:\n",
    "        # The image is a mask in which pixels should be zero or one.\n",
    "        # block_reduce may have changed some of the values, so reset here.\n",
    "        reduced_data = reduced_data > 0\n",
    "        # Set the image scale limits appropriately.\n",
    "        scale_args = dict(vmin=0, vmax=1)\n",
    "    else:\n",
    "        scale_args = dict(norm=norm)\n",
    "\n",
    "    im = ax.imshow(reduced_data, origin='lower',\n",
    "                   cmap=cmap, extent=extent, aspect='equal', **scale_args)\n",
    "\n",
    "    if show_colorbar:\n",
    "        # I haven't a clue why the fraction and pad arguments below work to make\n",
    "        # the colorbar the same height as the image, but they do....unless the image\n",
    "        # is wider than it is tall. Sticking with this for now anyway...\n",
    "        # Thanks: https://stackoverflow.com/a/26720422/3486425\n",
    "        fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        # In case someone in the future wants to improve this:\n",
    "        # https://joseph-long.com/writing/colorbars/\n",
    "        # https://stackoverflow.com/a/33505522/3486425\n",
    "        # https://matplotlib.org/mpl_toolkits/axes_grid/users/overview.html#colorbar-whose-height-or-width-in-sync-with-the-master-axes\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3956d583-ad7b-448e-b8b6-1912337d32dc",
   "metadata": {},
   "source": [
    "## Exploring Biases, Headers and Fits files using astropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8036ede8-04d7-42d4-a3b1-a6ed509467c5",
   "metadata": {},
   "source": [
    "Lets set the paths and open a single bias files to plot up and explore. \n",
    "\n",
    "Begin by setting the correct path of the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c5c372-3cc1-41cc-83b7-0bf79135ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the paths of the raw data.\n",
    "#raw_path = add path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac90447b-b94f-4278-8196-84d881241a1b",
   "metadata": {},
   "source": [
    "Use pyfits (astropy.io.fits) to open the first bias file. We will use this bias file explore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567620e-36e5-4a3a-8fc9-d1a4de6acafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the first bias image\n",
    "#bias1 = pyfits.open()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c5ac88-e799-4e3c-ab2a-6e71195983ea",
   "metadata": {},
   "source": [
    "Once the bias is open explore/print the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a0f3f8-9f31-481f-b92c-2cf653321ab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grab and then print the header \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff31084-01ac-43bf-adea-b4654c9d6a79",
   "metadata": {},
   "source": [
    "Once you print the header grab the following information from the header to store in a Table \n",
    "filename, image type, object name, filter, exposure time, airmass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f025745-0c98-42fc-a167-81b055ea930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add code here to print specific peices of the header pieces of the header as above \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9121b297-2933-410d-b424-6200f04d4b72",
   "metadata": {},
   "source": [
    "Now that you have obtained the the informaiton from the header, lets:\n",
    "1. Plot the first bias (highly reccomend either using a zscale for the colorbar or vmin,vmax that is about 1 std -/+ from median )\n",
    "2. Use the data to compute summary statistics about the bias (e.g., min, max, median, mean, std, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217444c8-25fa-4950-9b72-033353fe45d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- insert code here that will compute basic statistics of the first bias and plot it. Do not use show image code just yet ---\n",
    "#HINT for plotting use either -/+ 1 std for vmin/vmax or better use Zscale \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cddf9f2-4814-4bda-b902-adc0f70ed2e4",
   "metadata": {},
   "source": [
    "## Comparing Biases \n",
    "\n",
    "Now that you have explored the first bias; laod in the second bias and answer the question: \n",
    "\n",
    "Q : How different are the First and second biases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c26904-d0a3-4427-8bf2-f1cefd3569df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- insert code here that will compute basic statistics of the second bias and plot it. Do not use show image code just yet ---\n",
    "#HINT for plotting use either -/+ 1 std for vmin/vmax or better use Zscale \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679c9efb-42b5-4d1f-bfde-ec0e75860643",
   "metadata": {},
   "source": [
    "Q : How different are the First and second biases?\n",
    "\n",
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991bde32-0361-4d47-a0d8-05e926a5ce43",
   "metadata": {},
   "source": [
    "## Exploring the Night Directory and Stacking the Biases "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de9c84-4249-4e26-9b11-2892d3fd72a1",
   "metadata": {},
   "source": [
    "We can exlpore all of the files in the night directory using a very useful package called ccdproc (i.e. CCD Process). This is a pythonic version of the IRAF tasks called CCDProc. The command we will use to explore the directory is called ImageFileCollection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc60a2-c2e3-4911-b434-563a96589ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- add information you would like from the keys --- \n",
    "#keys = [add keywords here]\n",
    "ic1 = ImageFileCollection(raw_path, keywords=keys)\n",
    "summary_tab = ic1.summary\n",
    "summary_tab.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37536220-aaeb-413e-9a42-3a60b48c24b5",
   "metadata": {},
   "source": [
    "## Plot the airmass distribution \n",
    "\n",
    "It may be worth looking at the information in the headers. Lets plot the distribution of airmasses that we have sampled through out the night and answer the question : What do you notice about the airmass distirbution? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72ba2a-89e4-4a13-a006-4dadaec97ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add airmass distribtion here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2dbf9-a2eb-45be-983c-faa1693c26f1",
   "metadata": {},
   "source": [
    "Q: What do you notice about the airmass distirbution? \n",
    "\n",
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3185cc2-acc2-48d9-984d-f470a3acf949",
   "metadata": {},
   "source": [
    "## Stacking the Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86e0e60-1def-4fef-af7e-1105b0ad6736",
   "metadata": {},
   "source": [
    "Now our task is to look what happens when we combine all of the biases into a single median stacked bias which we will call the \"Master Bias\" Once you compute the median bias (across all biases) plot it and compare its statistics to the first bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8593fd2b-2237-417e-ac07-942d2b1ea726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code here to stack the biases using a median, compute the final statistics for the stacked bias and plot it.\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffaacae-3a2a-47f1-9bb5-7754e558c4d5",
   "metadata": {},
   "source": [
    "Q: What do you notice about the \"Master bias\" comapred to a single bias frame? \n",
    "\n",
    "A:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ddab7f-537d-4f3c-aa94-5ed8f1462dfc",
   "metadata": {},
   "source": [
    "## Measuring the Dark Current\n",
    "\n",
    "The Dark Current Can be important. Lets check if it is or not. \n",
    "\n",
    "To do this we need to determine how different is the dark frame from the master bias frame *IN COUNTS* and then divide that by the exposure time of the dark frame. To detemrine if it matters we can then compare this against the Readnoise to determine the total exposure time required to achieve 1 electron per pixel in dark current. \n",
    "\n",
    "Q: A. How large is the bias current in electrons per second per pixel?; B. How does it compare to the readnoise, and C. How long does an exposure time \n",
    "\n",
    "For this excerise compute the bias current in the longest and shortest exposed dark frame! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752f276-a840-4bb4-9e97-bce6b13b5b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- add code here\n",
    "# open the longest dark image\n",
    "from astropy.stats import sigma_clip\n",
    "dark1 = pyfits.open(raw_path + 'dark0004.fits')[0]\n",
    "diffs =  dark1.data - master_bias\n",
    "filtered_diff= sigma_clip(diffs, sigma=3, maxiters=None,\n",
    "                           cenfunc=np.median, masked=False, copy=False)\n",
    "\n",
    "# compare it against the bias \n",
    "\n",
    "# compute the dark current accounting for the gain and darktime\n",
    "\n",
    "#print out the amount of dark current, compare it to the read noise, and compute the exopsure time required to make the Dark Current larger than the read noise\n",
    "\n",
    "print(np.mean(filtered_diff))\n",
    "DC = abs(np.mean(diffs)) * bias1.header['GAIN'] / dark1.header['DARKTIME']\n",
    "print('The expected Dark Current is %.2e electrons per second per pixel'%DC)\n",
    "print('The Readnoise is %.2f electrons'%bias1.header['RDNOISE'])\n",
    "print('Thus the exposure time required to make the DC larger than the read noise is %i seconds'%(bias1.header['RDNOISE']**2/ DC )) \n",
    "#NOTE  -- The square is b/c the RN = sqrt(N_electrons)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba7f2bc-cce8-4e07-a907-2b7828858b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q : \n",
    "\n",
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64ad42e-aac7-4290-8658-b534daaf0aa9",
   "metadata": {},
   "source": [
    "## Stacking a Bandpass Specific Flat \n",
    "\n",
    "Now that we have a \"Master Bias\" from median stacking all of our bias frames, our next task is to stack all of the flats (using the same procedure as for the biases). \n",
    "\n",
    "To do this :\n",
    "1. Choose a bandpass to work with\n",
    "2. Plot and compute the statistics for a single flat frame of you choice\n",
    "3. Median Stack all the *!bias subtracted!* flats in a bandpass of your choice \n",
    "4. Plot and compute the statistics for the median stacked flat frame in the bandpass of your chocie and compare against the single flat (from step 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6e7b6-1c3c-4fca-aba8-a0e7a98eb703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Answer goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c6507d-4d9c-4bde-8982-0495e3a25970",
   "metadata": {},
   "source": [
    "# Basic Reduction of an Object Frame \n",
    "\n",
    "Lets now :\n",
    "1. Read in single object/science frame of your choice in the same bandpass you choose above.\n",
    "2. Plot the object frame\n",
    "3. Account for the bias (subtract) and flat (divide) and plot the 'finalized' image. HINT : the master should be normalized by the maximum and bias corrected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b9c21f-61e1-4b36-bab4-18dca1b4bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Read in the object \n",
    "\n",
    "\n",
    "# ---grab the fits data \n",
    "\n",
    "#---plot the object data be sure to note in the title the object name; bandpass; exposure time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c013ae-9011-42a9-9a59-d44d0596d8cb",
   "metadata": {},
   "source": [
    "## \"Clean\" the image by account for the bias and flat\n",
    "\n",
    "Start by accounting for the bias and flat on the object frame and then plot it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd62dae-d2fb-4cd8-b73c-5e9b10fa468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Clean\" the object data by accounting for the flat and bias! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32095012-a724-4565-8570-21bceca1a22b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot the  \"CLEANED\" object data \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9eb47a-564a-4a93-a5de-3b3d73140472",
   "metadata": {},
   "source": [
    "# Trim and fix the bad columns \n",
    "\n",
    "As you can tell, there is a \"overscan\" region (that contains the bias) and there are bad columns. We want to:\n",
    "1. Trim the overscan region\n",
    "2. Write some functions that can account for the bad columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1587e01-8675-43dd-96b8-24df97b838a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---defintion to fix bad pixels-----\n",
    "def fixpixels(image,badpixels):\n",
    "    '''\n",
    "    Code that will apply a 'fix pix' base routine on a series of bad columns.\n",
    "    INPUT : \n",
    "    -Image data to be cleaned \n",
    "    -badpixels (Nx4 array) -- the [Xstart, Xend, Ystart, Yend] of the bad pixels/columns to be interoplated over \n",
    "    OUTPUT : Cleaned image data \n",
    "\n",
    "    '''\n",
    "\n",
    "    \n",
    "    M = np.full((np.shape(image.data)[0],np.shape(image.data)[1]),False)\n",
    "    for j in range(len(badpixels)):\n",
    "        M[badpixels[j][2]:badpixels[j][3],badpixels[j][0]:badpixels[j][1]] = True\n",
    "    X = np.ma.array(image.data,mask=M)\n",
    "    cleaned_image =  fixpix_baseroutine(X.data,X.mask)\n",
    "    return cleaned_image\n",
    "\n",
    "\n",
    "# --- base routine to fix pixels by interoplating over the bad/masked regions\n",
    "def fixpix_baseroutine(data, mask, kind='linear'):\n",
    "    '''\n",
    "    Baserounte Code that will apply a fix the pixels by taking all masked vlaues in the array and doing a linear interpolation over the masked pixels \n",
    "    INPUT : Image data to be cleaned, mask from the array, kind = 'linear' which is the interoplation type\n",
    "    OUTPUT : Cleaned image data \n",
    "    '''\n",
    "    \"\"\"Interpolate 2D array data in rows\"\"\"\n",
    "    import numpy as np\n",
    "    from scipy.interpolate import interp1d\n",
    "    if data.shape != mask.shape: #mask and data in image must have same dimensions\n",
    "        raise(ValueError)\n",
    "\n",
    "    if not np.any(mask):\n",
    "        return data # if it doesnt just return the data\n",
    "\n",
    "    x = np.arange(0, data.shape[1])\n",
    "    for row, mrow in zip(data, mask):\n",
    "        if np.any(mrow):  # Interpolate if there's some pixel missing\n",
    "            valid = (mrow == np.False_)\n",
    "            invalid = (mrow == np.True_)\n",
    "\n",
    "            itp = interp1d(x[valid], row[valid], kind=kind, copy=False) \n",
    "            row[invalid] = itp(x[invalid]).astype(row.dtype)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56705ee2-8a9b-445e-af12-eb336ea10045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the above codes to fix the bad pixels by clean_obj_fixpix = fixpixels(clean_obj_data)\n",
    "# -- uncomment below\n",
    "#badpixels = [[Xstart,Xend,Ystart,Yend], ...]\n",
    "#trimed_clean_obj = fixpixels(image,badpixels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda95188-9375-4d4c-93bb-b396ecdb9a6c",
   "metadata": {},
   "source": [
    "Finally with the cleaned object data that whose pixels have been fixed please plot the final CCD reduced image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3726ef1-79f3-4782-9716-532b37011455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the  \"CLEANED\" object data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b071d6-5aea-4218-b2a3-f41829123047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
